{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24901aa7-2867-4c20-a544-585120543fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import Magics, cell_magic, line_magic, magics_class\n",
    "from pexpect import spawn\n",
    "\n",
    "TIMEOUT = 60\n",
    "PROG = \"hive\"\n",
    "PROMPT = [\"\\r\\n    > \", \"\\r\\nhive> \"]\n",
    "QUIT = \"quit;\"\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class Magic(Magics):\n",
    "    def __init__(self, shell):\n",
    "        super().__init__(shell)\n",
    "        self.app = spawn(PROG, timeout=60)\n",
    "        self.app.expect(PROMPT)\n",
    "\n",
    "    @cell_magic\n",
    "    def hive(self, line, cell):\n",
    "        cell_lines = [cell_line.strip() for cell_line in cell.split(\"\\n\")]\n",
    "        cell_lines = [cell_line for cell_line in cell_lines if cell_line != \"\"]\n",
    "        for cell_line in cell_lines:\n",
    "            self.app.sendline(cell_line)\n",
    "            self.app.expect(PROMPT, timeout=TIMEOUT)\n",
    "            output = self.app.before.decode()\n",
    "            output = output.replace(\"\\r\\n\", \"\\n\")\n",
    "            output = output.split(\"\\n\")\n",
    "            output = [output_line.strip() for output_line in output]\n",
    "            for output_line in output:\n",
    "                if output_line not in cell_lines:\n",
    "                    print(output_line)\n",
    "        return None\n",
    "\n",
    "    @line_magic\n",
    "    def quit(self, line):\n",
    "        self.app.sendline(QUIT)\n",
    "\n",
    "\n",
    "def load_ipython_extension(ip):\n",
    "    ip.register_magics(Magic(ip))\n",
    "\n",
    "\n",
    "load_ipython_extension(ip=get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9623a7-476a-4dde-aaa2-c1d1351cbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_01/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7233eda9-ce08-452b-9547-2be369b547bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup        677 2023-05-24 19:28 /tmp/data.tsv\n",
      "drwxrwx---   - root supergroup          0 2023-05-24 19:25 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-05-24 19:27 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84a3b8b-8d05-4e25-8c4e-88de3661913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TED FIELDS TERMINATED BY '\\t';G, col2 STRING, col3 INT ) ROW FORMAT DELIMI \n",
      "OK\n",
      "Time taken: 17.743 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "CREATE TABLE data ( col1 STRING, col2 STRING, col3 INT ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8711eda-36e8-4899-83c2-f30647345146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to table default.data\n",
      "OK\n",
      "Time taken: 2.105 seconds\n",
      "OK\n",
      "B\t1999-08-28\t14\n",
      "E\t1999-12-06\t12\n",
      "E\t1993-07-21\t17\n",
      "C\t1991-02-12\t13\n",
      "E\t1995-04-25\t16\n",
      "A\t1992-08-22\t14\n",
      "B\t1999-06-11\t12\n",
      "E\t1993-01-27\t13\n",
      "E\t1999-09-10\t11\n",
      "E\t1990-05-03\t16\n",
      "E\t1994-02-14\t5\n",
      "A\t1988-04-27\t12\n",
      "A\t1990-10-06\t10\n",
      "E\t1985-02-12\t16\n",
      "E\t1998-09-14\t16\n",
      "B\t1994-08-30\t17\n",
      "A\t1997-12-15\t13\n",
      "B\t1995-08-23\t10\n",
      "B\t1998-11-22\t13\n",
      "B\t1997-04-09\t14\n",
      "E\t1993-12-27\t18\n",
      "E\t1999-01-14\t15\n",
      "A\t1992-09-19\t18\n",
      "B\t1993-03-02\t14\n",
      "B\t1999-10-21\t13\n",
      "A\t1990-08-31\t12\n",
      "C\t1994-01-25\t6\n",
      "E\t1990-02-09\t18\n",
      "A\t1990-09-26\t14\n",
      "A\t1993-05-08\t16\n",
      "B\t1995-09-06\t14\n",
      "E\t1991-02-18\t14\n",
      "A\t1993-01-11\t14\n",
      "A\t1990-07-22\t18\n",
      "C\t1994-09-09\t15\n",
      "C\t1994-07-27\t7\n",
      "D\t1990-10-10\t15\n",
      "A\t1990-09-05\t11\n",
      "B\t1991-10-01\t15\n",
      "A\t1994-10-25\t13\n",
      "Time taken: 2.558 seconds, Fetched: 40 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive \n",
    "LOAD DATA INPATH '/tmp/data.tsv' OVERWRITE INTO TABLE data; \n",
    "SELECT * FROM data;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2496b6b2-74ea-46ab-b485-1078310104e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230524194516_1e75fa9d-539d-4587-9e0a-ad068358cb2e\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "java.io.IOException: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:345)\n",
      "at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:253)\n",
      "at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)\n",
      "at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)\n",
      "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)\n",
      "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)\n",
      "at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)\n",
      "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:414)\n",
      "at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:151)\n",
      "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)\n",
      "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)\n",
      "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)\n",
      "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)\n",
      "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "at org.apache.hadoop.util.RunJar.run(RunJar.java:244)\n",
      "at org.apache.hadoop.util.RunJar.main(RunJar.java:158)\n",
      "Caused by: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateYarnException(RPCUtil.java:75)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:116)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:284)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "at com.sun.proxy.$Proxy72.submitApplication(Unknown Source)\n",
      "at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:283)\n",
      "at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:297)\n",
      "at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:329)\n",
      "... 35 more\n",
      "Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException): Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)\n",
      "at org.apache.hadoop.ipc.Client.call(Client.java:1495)\n",
      "at org.apache.hadoop.ipc.Client.call(Client.java:1394)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\n",
      "at com.sun.proxy.$Proxy71.submitApplication(Unknown Source)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:281)\n",
      "... 48 more\n",
      "Job Submission failed with exception 'java.io.IOException(org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      ")'\n",
      "FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask. org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%hive \n",
    "SELECT col1, COUNT(*) FROM data GROUP BY col1 ORDER BY col1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f4fe5d-21ea-4104-82e6-fbf8de976ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230524195731_0cd97d71-b016-47f8-bdb6-51132f61fbfa\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "java.io.IOException: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:345)\n",
      "at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:253)\n",
      "at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)\n",
      "at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)\n",
      "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)\n",
      "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)\n",
      "at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)\n",
      "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:414)\n",
      "at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:151)\n",
      "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)\n",
      "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)\n",
      "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)\n",
      "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)\n",
      "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "at org.apache.hadoop.util.RunJar.run(RunJar.java:244)\n",
      "at org.apache.hadoop.util.RunJar.main(RunJar.java:158)\n",
      "Caused by: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateYarnException(RPCUtil.java:75)\n",
      "at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:116)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:284)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "at com.sun.proxy.$Proxy72.submitApplication(Unknown Source)\n",
      "at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:283)\n",
      "at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:297)\n",
      "at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:329)\n",
      "... 35 more\n",
      "Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException): Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n",
      "at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)\n",
      "at org.apache.hadoop.ipc.Client.call(Client.java:1495)\n",
      "at org.apache.hadoop.ipc.Client.call(Client.java:1394)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\n",
      "at com.sun.proxy.$Proxy71.submitApplication(Unknown Source)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:281)\n",
      "... 48 more\n",
      "Job Submission failed with exception 'java.io.IOException(org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      ")'\n",
      "FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask. org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation. Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:1478, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:4>\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.throwInvalidResourceException(SchedulerUtils.java:396)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkResourceRequestAgainstAvailableResource(SchedulerUtils.java:387)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:296)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:243)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:209)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:540)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:393)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:333)\n",
      "at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:667)\n",
      "at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:267)\n",
      "at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:531)\n",
      "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)\n",
      "at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)\n",
      "at java.security.AccessController.doPrivileged(Native Method)\n",
      "at javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)\n",
      "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT COUNT(*) FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd1996-6e1f-43be-8d77-ec51ce2b9063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
